import openai
import sounddevice as sd
import numpy as np
import scipy.io.wavfile as wav
import os

# CONFIGURANDO O CLIENTE OPENAI
client = openai.OpenAI(api_key="API-KEY")

# ğŸ¤ FunÃ§Ã£o para gravar Ã¡udio do usuÃ¡rio
def gravar_audio(nome_arquivo="audio.wav", duracao=5, samplerate=44100):
    print("ğŸ¤ Gravando... Fale agora!")
    audio = sd.rec(int(duracao * samplerate), samplerate=samplerate, channels=1, dtype=np.int16)
    sd.wait()
    wav.write(nome_arquivo, samplerate, audio)
    print("âœ… GravaÃ§Ã£o finalizada!")

# ğŸ“ FunÃ§Ã£o para transcrever Ã¡udio com Whisper (NOVA API)
def transcrever_audio(nome_arquivo="audio.wav"):
    with open(nome_arquivo, "rb") as audio_file:
        resposta = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file
        )
    return resposta.text  # Acessando o texto da resposta corretamente

# ğŸ”Š FunÃ§Ã£o para converter texto em Ã¡udio (Text-to-Speech)
def texto_para_audio(texto, nome_arquivo="resposta.mp3"):
    resposta = client.audio.speech.create(
        model="tts-1",
        voice="nova",
        input=texto
    )

    with open(nome_arquivo, "wb") as f:
        f.write(resposta.content)  

    print("ğŸ”Š Ãudio gerado:", nome_arquivo)
    
    # ğŸ§ Reproduzir o Ã¡udio automaticamente
    if os.name == "nt":
        os.system(f"start {nome_arquivo}")  # Windows
    else:
        os.system(f"mpg123 {nome_arquivo}")  # Linux/Mac

# ğŸ¤– FunÃ§Ã£o principal do Chatbot
def chatbot_com_voz():
    gravar_audio()
    texto_usuario = transcrever_audio()
    print("ğŸ‘¤ UsuÃ¡rio:", texto_usuario)

    resposta = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": texto_usuario}]
    ).choices[0].message.content

    print("ğŸ¤– Chatbot:", resposta)

    texto_para_audio(resposta)
    print("ğŸ§ Ouvindo resposta...")

# ğŸš€ Executar chatbot com voz
chatbot_com_voz()
